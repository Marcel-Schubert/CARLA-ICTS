# CI3P+: On cognitive informed pedestrian path prediction in pedestrian-vehicle interactions

This repository contains the code for the bachelor thesis *CI3P+: On cognitive informed pedestrian path prediction in pedestrian-vehicle interactions*.
The code is based on the repository of CARLA-ICTS1 https://github.com/nipwal/CARLA-ICTS.


## Installation
### Install Carla 0.9.15
The code is based on CARLA 0.9.15. The installation instructions can be found here: https://carla.readthedocs.io/en/0.9.15/start_quickstart/.
After the installation you may need to install [C++ redistributable](https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist) and [DirectX runtime](https://www.microsoft.com/de-de/download/details.aspx?id=35) .

### Setup python
To set up python, we recommend using anaconda, or some sort of virtual environment.
Make sure to install python 3.7, as newer versions may break the code.
The required python packages can be installed with:
    `pip install -r req.txt`.

## CARLA-ICTS2
The main file to export training data for the pedestrian path prediction is `export_pp_data.py` and
will be exported to the `P3VI/data` directory by default.
The training data can be generated by running the following command:
> `python export_pp_data.py`

This will generate all data by scenario.
To adjust the scenarios generated comment in/out the scenarios in the beginning of the file.

To clean the data, and generate a joined file for all scenarios, run the following command:
> `python convert_single_to_full.py`

A full set of training data is provided in the `pedestrian_path_prediction/data/new_car` directory,
which was used to train the models in the thesis.
The exporting of the data will take a long time, about 1-2 days if run on a single machine.

## Training path prediction models:
All methods are stored in the `pedestrian_path_prediction` directory, including
a training/test script for each method.
All methods are delivered with two models used in the thesis.
These models are stored in the `pedestrian_path_prediction/saved_models` directory.
The subfolder `15_20` and `60_80` contain the models for the respective scenarios.

In all test cases the files are set up to use a pre-trained model
from the `pedestrian_path_prediction/saved_models` directory.


### Train M3P
To adjust the setting change `n_pred` and `n_obs` in the beginning of the `ped_path_predictor/M3P/train.py` file.

#### Train:
To train the M3P model, run the following command:
> `python ped_path_predictor/M3P/train.py`

#### Test:
For testing the model, run the following command:
> `python ped_path_predictor/M3P/train.py --test`

### Train P3VI/CI3P
To adjust the setting change `n_pred` and `n_obs` in the beginning of the `ped_path_predictor/P3VI/train.py` file.

#### Train:
To train the M3P model, run the following command:
> `python ped_path_predictor/P3VI/train.py`

#### Test:
For testing the model, run the following command:
> `python ped_path_predictor/P3VI/train.py --test`

### Train CI3P+ and variants
All CI3P+ methods are found in the `ped_path_predictor/CI3P` directory.
Each subdirectory contains a training script for the respective method.
To adjust the setting change `n_pred` and `n_obs` in the beginning of their training file.

#### Train:

CI3P+(Car): `python ped_path_predictor/CI3P/CI3P_Car_Only/train.py`

CI3P+(Cognitive): `python ped_path_predictor/CI3P/CI3P_Cognitive_Only/train.py`

CI3P+(Cognitive+Car): `python ped_path_predictor/CI3P/CI3P_both/train.py`

C-CI3P+(Car): `python ped_path_predictor/CI3P/CVAE_CI3P_Car_Only/train.py`

C-CI3P+(Cognitive): `python ped_path_predictor/CI3P/CVAE_CI3P_Cognitive_Only/train.py`

C-CI3P+(Cognitive+Car): `python ped_path_predictor/CI3P/CVAE_CI3P_both/train.py`

#### Test:

CI3P+(Car): `python ped_path_predictor/CI3P/CI3P_Car_Only/train.py --test`

CI3P+(Cognitive): `python ped_path_predictor/CI3P/CI3P_Cognitive_Only/train.py --test`

CI3P+(Cognitive+Car): `python ped_path_predictor/CI3P/CI3P_both/train.py --test`

C-CI3P+(Car): `python ped_path_predictor/CI3P/CVAE_CI3P_Car_Only/train.py --test`

C-CI3P+(Cognitive): `python ped_path_predictor/CI3P/CVAE_CI3P_Cognitive_Only/train.py --test`

C-CI3P+(Cognitive+Car): `python ped_path_predictor/CI3P/CVAE_CI3P_both/train.py --test`


### Train AutoBots and variants
All AutoBots methods are found in the `ped_path_predictor/AutoBots` directory.
`ped_path_predictor/autobots/AutoBots/models/autobot_ego.py` is the original AutoBotsEgo model.
`ped_path_predictor/autobots/AutoBots/models/autobot_ego_cogV2.py` is the AutoBotsEgo model with
the added cross-modal attention mechanism.
To adjust the setting change `n_pred` and `n_obs` in the beginning of their training file.

#### Train:
AutBots: `python ped_path_predictor/autobots/autobot_wrapper.py`

AutoBots(C as Agent): `python ped_path_predictor/autobots/autobot_wrapper_cognitive.py`

AutoBots(X-Att): `python ped_path_predictor/autobots/autobot_wrapper_custom_cognitiveV2.py`

#### Test:
AutBots: `python ped_path_predictor/autobots/autobot_wrapper.py --test`

AutoBots(C as Agent): `python ped_path_predictor/autobots/autobot_wrapper_cognitive.py --test`

AutoBots(X-Att): `python ped_path_predictor/autobots/autobot_wrapper_custom_cognitiveV2.py --test`


### BiTrap:
The BiTrap model is found in the `ped_path_predictor/BiTrap` directory.
To adjust the setting change `n_pred` and `n_obs` in the beginning of the `ped_path_predictor/BiTrap/trainBitrapNew.py` file.
Additionally, the config file `ped_path_predictor/BiTrap/bitrap_np_ICTS.yml` needs to be adjusted.
Under `MODEL.PRED_LEN` and `MODEL.INPUT_LENT` the respective values for `n_pred` and `n_obs` need to be set.

#### Train:
To train the BiTrap model, run the following command:
> `python ped_path_predictor/BiTrap/trainBitrapNew.py`

#### Test:
To test the BiTrap model, run the following command:
> `python ped_path_predictor/BiTrap/trainBitrapNew.py --test`

### GroupNet:
The GroupNet model is found in the `ped_path_predictor/GroupNet` directory.
To adjust the setting change `n_pred` and `n_obs` in the beginning of the `ped_path_predictor/GroupNet/train_group_net.py` file.

#### Train:
To train the GroupNet model, run the following command:
> `python ped_path_predictor/GroupNet/train_group_net.py`

#### Test:
To test the GroupNet model, run the following command:
> `python ped_path_predictor/GroupNet/train_group_net.py --test`





# For completeness the instructions of CARLA-ICTS1 are included below:
## Installation
#### Install CARLA

See here - https://carla.readthedocs.io/en/0.9.13/start_quickstart/
**Important:** The code is only compatible with CARLA version 0.9.13. 

#### Install python 3.7 (newer version may break the code) and anaconda
The required python packages can be install with:
    `conda create --name <envname> --file req.yaml`.
Alternatively, to build an environment from scratch, the code is mostly based on tensorflow, pytorch,
pandas, matplotlib and scipy.

#### IS-DESPOT-p and HyLEAP

1. Install a c++ compiler >=7.3.0, g++ is recommended, and make

    `sudo apt-get install build-essential `
    `sudo apt-get install make`
2. Navigate to the following directories (in that order) and run `make`:
    - `./ISDESPOT/isdespot-ped-pred/is-despot/`
    - `./ISDESPOT/isdespot-ped-pred/is-despot/problems/isdespotp_car`
    - `./HyLEAP/smart-car-sim-master/is-despot/`
    - `./HyLEAP/smart-car-sim-master/is-despot/problems/hybridVisual_car`

## Run experiments

### HyREAL-lite
#### Training
To train HyREAL-lite from scratch  on the whole benchmark execute the following line,
>`python train_hyreal_a2c.py --server --cuda --port=<port> --config=<config>`.

The argument `--server` specifies to use the carla config for the server,
while `--cuda` specifies that the RL-agent is run on GPU. The carla port is configured
using `--port` and the configuration for the RL-agent is passed via `--config`.

#### Testing

To test HyREAL-lite for a specific scenario `scenario` $\in$ `[01_int, 02_int, 03_int, 01_non_int, 02_non_int, 03_non_int]`, run the following command,
> `python eval_learner.py --server --port=<port> --test=scenario --agent=hyreal`

In order to execute all scenarios at once use th following command,
> `python eval_learner.py --server --port=<port> --test=all --agent=hyreal`


### A2C-CADRL
#### Training
To train A2C-CADRL from scratch  on the whole benchmark execute the following line,
>`python train_c2a.py --server --cuda --port=<port> --config=<config>`.

The argument `--server` specifies to use the carla config for the server,
while `--cuda` specifies that the RL-agent is run on GPU. The carla port is configured
using `--port` and the configuration for the RL-agent is passed via `--config`.

#### Testing

To test A2C-CADRL for a specific scenario `scenario` $\in$ `[01_int, 02_int, 03_int, 01_non_int, 02_non_int, 03_non_int]`, run the following command,
> `python eval_learner.py --server --port=<port> --test=scenario --agent=a2c`

In order to execute all scenarios at once use th following command,
> `python eval_learner.py --server --port=<port> --test=all --agent=a2c`

### NavSAC 
#### Training
To train NavSAC from scratch run,
> `python3 train_sac.py --server --cuda --port=<port> config=<config>`.

#### Testing

To test NavSAC for a specific scenario `scenario` $\in$ `[01_int, 02_int, 03_int, 01_non_int, 02_non_int, 03_non_int]`, run the following command,
> `python eval_sac.py --server --port=<port> --test=scenario`

In order to execute all scenarios at once use th following command,
> `python eval_sac.py --server --port=<port> --test=all`

### HyLEAP
### Training
HyLEAP can be trained by running,
> `python train_hyleap.py --port=<port>`.

The parameters can be adjusted in `hyleap/hybrid_visual.py`
### Testing
To test HyLEAP for a specific scenario `scenario` $\in$ `[01_int, 02_int, 03_int, 01_non_int, 02_non_int, 03_non_int]`, run the following command,
> `python eval_hyleap.py  --port=<port> --despot_port=<despot_port> --test=scenario`

The argument `--desport_port` specifies the port over which the RL-agent communicates with the planner.
To run the evaluation for all scenarios the following command can be used,
> `python eval_hyleap.py  --port=<port> --despot_port=<despot_port> --test=all`

### IS-DESPOT(*)
For IS-DESPOT(*) no training is required. The evaluation for `scenario` $\in$ `[01_int, 02_int, 03_int, 01_non_int, 02_non_int, 03_non_int]` can be run via
> `python eval_isdespot.py --server --port=<port> --despot_port=<despot_port> --test=scenario`
> `python eval_isdespot_star.py --server --port=<port> --despot_port=<despot_port> --test=scenario`

To run, the evaluation for all scenarios run:
> `python eval_isdespot.py --server --port=<port> --despot_port=<despot_port> --test=all`
> `python eval_isdespot_star.py --server --port=<port> --despot_port=<despot_port> --test=all`

## License
Shield: [![CC BY-NC-SA 4.0][cc-by-nc-sa-shield]][cc-by-nc-sa]

This work is licensed under a
[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License][cc-by-nc-sa].

[![CC BY-NC-SA 4.0][cc-by-nc-sa-image]][cc-by-nc-sa]

[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/
[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png
[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg
